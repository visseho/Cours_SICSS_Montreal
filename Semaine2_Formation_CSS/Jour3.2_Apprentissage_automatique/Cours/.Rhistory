gather(word, count, -id_num, -author) %>%
# calculate averge document word usage by author
group_by(author, word) %>%
summarise(avg_count = mean(count)) %>%
spread(author, avg_count) %>%
knitr::kable()
hm_tfm1
author_data <-
hm_tfm %>%
ungroup() %>%
filter(is.na(author) | author != "Jay") %>%
mutate(author2 = case_when(.$author == "Hamilton" ~ 1,
.$author == "Madison" ~ -1,
TRUE ~ NA_real_))
View(author_data)
hm_fit <- lm(author2 ~ upon + there + consequently + whilst,
data = author_data)
hm_fit
author_data <- author_data %>%
add_predictions(hm_fit) %>%
mutate(pred_author = if_else(pred >= 0, "Hamilton", "Madison"))
ctable(author_data$pred_author, author_data$author, "c")
library(summarytools)
ctable(author_data$pred_author, author_data$author, "c")
author_data %>%
filter(!is.na(author)) %>%
group_by(author) %>%
summarise(`Proportion Correct` = mean(author == pred_author))
crossv_loo <- function(data, id = ".id") {
modelr::crossv_kfold(data, k = nrow(data), id = id)
}
cv <- author_data %>%
filter(!is.na(author)) %>%
crossv_loo()
models <- purrr::map(cv$train, ~ lm(author2 ~ upon + there + consequently + whilst,
data = ., model = FALSE))
test <- map2_df(models, cv$test,
function(mod, test) {
add_predictions(as.data.frame(test), mod) %>%
mutate(pred_author =
if_else(pred >= 0, "Hamilton", "Madison"),
correct = (pred_author == author))
})
test %>%
group_by(author) %>%
summarise(mean(correct))
author_data %>%
filter(is.na(author)) %>%
select(id_num, pred, pred_author) %>%
knitr::kable()
disputed_essays <- filter(author_data, is.na(author))$id_num
ggplot(mutate(author_data,
author = fct_explicit_na(factor(author), "Disputed")),
aes(y = id_num, x = pred, colour = author, shape = author)) +
geom_ref_line(v = 0) +
geom_point() +
scale_y_continuous(breaks = seq(10, 80, by = 10),
minor_breaks = seq(5, 80, by = 5)) +
scale_color_manual(values = c("Madison" = "blue",
"Hamilton" = "red",
"Disputed" = "black")) +
scale_shape_manual(values = c("Madison" = 16, "Hamilton" = 15,
"Disputed" = 17)) +
labs(colour = "Author", shape = "Author",
y = "Federalist Papers", x = "Predicted values")
View(corpus_tidy_text_tfidf)
View(corpus_tidy)
inspect(corpus_dtm[1:5,1:8])
graph_doc <- function(donnee){
ggplot(donnee) +
geom_col(aes(x = reorder(word, desc(n)), y = n, fill = word), show.legend = FALSE) +
labs(x = "Word") +
coord_flip() #+
#guides(color = FALSE)
}
doc12 <- corpus_tidy_text %>%
filter(id_num == 12) %>%
group_by(word) %>%
count() %>%
arrange(desc(n))
doc12_10 <- doc12[1:10, ]
graph_doc(doc12_10)
graph_doc(doc24_10)
View(Hamilton)
View(kmean_out)
View(kmean_data)
hamilton_words <-
tibble(word = colnames(Hamilton_dtm))
View(hamilton_words)
hamilton_words <- bind_cols(hamilton_words, as_tibble(t(kmean_out$centers)))
View(hamilton_words)
View(hamilton_words)
View(hamilton_words)
top_word <-
hamilton_words %>%
pivot_longer(cols = c("1":"4"), names_to = "cluster", values_to = "value") %>%
group_by(cluster) %>%
top_n(10, value)
ggplot(top_word %>% filter(cluster == 2)) +
geom_col(aes(x = reorder(word, desc(value)), y = value)) +
coord_flip()
ggplot(top_word) +
geom_col(aes(x = reorder(word, desc(value)), y = value)) +
coord_flip() +
facet_wrap(~cluster)
ggplot(top_word) +
geom_col(aes(x = reorder(word, desc(value)), y = value)) +
coord_flip() +
facet_wrap(~cluster, scales = "free")
for (i in 1:4){
plot[[i]] <- ggplot(top_word %>% filter(cluster == i)) +
geom_col(aes(x = reorder(word, desc(value)), y = value)) +
coord_flip()
print(plot[[i]])
}
ggarrange(plot[[1]], plot[[2]], plot[[3]], plot[[4]], label.y = 1)
top_word_summary <-
top_word %>%
group_by(cluster) %>%
summarise(top_word = str_c(word, collapse = ", "))
top_word_summary
enframe(kmean_out$cluster, "id_num", "cluster") %>%
group_by(cluster) %>%
summarise(documents = str_c(id_num, collapse = ", "))
View(known_essays)
Style_words <-
tibble(word = c("although", "always", "commonly", "consequently",
"considerable", "enough", "there", "upon", "while", "whilst"))
View(corpus_tidy_short_t)
View(corpus_tidy)
View(corpus_tidy_short_t)
corpus_tidy_short_t <-
unnest_tokens(corpus_tidy, word, text) %>%
count(id_num, word) %>%
group_by(id_num) %>%
mutate(prop = n / sum(n) * 1000)
View(corpus_tidy_short_t)
corpus_tidy_short_t <-
corpus_tidy_short_t %>%
mutate(author = case_when(
id_num %in% hm ~ "Hamilton",
id_num %in% ma ~ "Madison",
id_num %in% ja ~ "Jay"))
corpus_tidy_short_t <-
corpus_tidy_short_t %>%
left_join(known_essays, by = "id_num")
corpus_tidy_short_t <-
corpus_tidy_short_t %>%
mutate(author = case_when(
id_num %in% hm ~ "Hamilton",
id_num %in% ma ~ "Madison",
id_num %in% ja ~ "Jay"))
corpus_tidy_short_t <-
unnest_tokens(corpus_tidy, word, text) %>%
count(id_num, word) %>%
group_by(id_num) %>%
mutate(prop = n / sum(n) * 1000)
corpus_tidy_short_t <-
unnest_tokens(corpus_tidy, word, text) %>%
count(id_num, word) %>%
group_by(id_num) %>%
mutate(prop = n / sum(n) * 1000)
corpus_tidy_short_t <-
corpus_tidy_short_t %>%
inner_join(Style_words, by = "word")
corpus_tidy_short_t <-
unnest_tokens(corpus_tidy, word, text) %>%
count(id_num, word) %>%
group_by(id_num) %>%
mutate(prop = n / sum(n) * 1000)
corpus_tidy_short_t <-
corpus_tidy_short_t %>%
inner_join(Style_words, by = "word")
corpus_tidy_short_t <-
corpus_tidy_short_t %>%
mutate(author = case_when(
id_num %in% hm ~ "Hamilton",
id_num %in% ma ~ "Madison",
id_num %in% ja ~ "Jay"))
corpus_tidy_short_t <-
corpus_tidy_short_t %>%
left_join(known_essays, by = c("id_num", "author"))
mots_auteurs <-
corpus_tidy_short_t %>%
filter(!is.na(author)) %>%
group_by(author, word) %>%
summarise(moyenne = mean(prop))
mots_auteurs <-
pivot_wider(mots_auteurs, names_from = word, values_from = moyenne)
mots_auteurs
hm_tfm <-
unnest_tokens(corpus_tidy, word, text) %>%
count(id_num, word) %>%
# term freq per 1000 words
group_by(id_num) %>%
mutate(count = n / sum(n) * 1000) %>%
select(-n) %>%
inner_join(Style_words, by = "word") %>%
# merge known essays
left_join(known_essays, by = "id_num") %>%
# make wide with each word a column
# fill empty values with 0
spread(word, count, fill = 0)
View(hm_tfm)
View(hm_tfm)
hm_tfm1 <-
hm_tfm %>%
# remove docs with no author
filter(!is.na(author)) %>%
# convert back to long (tidy) format to make it easier to summarize
gather(word, count, -id_num, -author) %>%
# calculate averge document word usage by author
group_by(author, word) %>%
summarise(avg_count = mean(count)) %>%
spread(author, avg_count) %>%
knitr::kable()
hm_tfm1
author_data <-
hm_tfm %>%
ungroup() %>%
filter(is.na(author) | author != "Jay") %>%
mutate(author2 = case_when(.$author == "Hamilton" ~ 1,
.$author == "Madison" ~ -1,
TRUE ~ NA_real_))
View(author_data)
View(author_data)
hm_fit <- lm(author2 ~ upon + there + consequently + whilst,
data = author_data)
hm_fit
summary(hm_fit)
author_data <- author_data %>%
add_predictions(hm_fit) %>%
mutate(pred_author = if_else(pred >= 0, "Hamilton", "Madison"))
library(summarytools)
View(author_data)
ctable(author_data$pred_author, author_data$author, "c")
author_data %>%
filter(!is.na(author)) %>%
group_by(author) %>%
summarise(`Proportion Correct` = mean(author == pred_author))
cv <- author_data %>%
filter(!is.na(author)) %>%
crossv_loo()
View(cv)
models <- purrr::map(cv$train, ~ lm(author2 ~ upon + there + consequently + whilst,
data = ., model = FALSE))
test <- map2_df(models, cv$test,
function(mod, test) {
add_predictions(as.data.frame(test), mod) %>%
mutate(pred_author =
if_else(pred >= 0, "Hamilton", "Madison"),
correct = (pred_author == author))
})
test %>%
group_by(author) %>%
summarise(mean(correct))
author_data %>%
filter(is.na(author)) %>%
select(id_num, pred, pred_author) %>%
knitr::kable()
data_essai <- data_frame(x = c(1,2,3,4,5), y = c(a,b,c,d,e))
data_essai <- data_frame(x = c(1,2,3,4,5), y = c("a","b","c","d","e"))
View(data_essai)
data_essai <- data_frame(id = c(1,2,3,4,5), y = c("a","b","c","d","e"), z = c("aa", "ab", "ac", "ad", "ae"))
data_essai_2 <- crossv_kfold(data_essai, k = 2, id = .id)
data_essai_2 <- crossv_kfold(data_essai, k = 2, id = ".id")
View(data_essai_2)
data_essai2_df <- tidy(data_essai_2)
View(data_essai_2)
data_essai_2$train$1
data_essai_2$test[[1]]
data_essai_2$test[[1]]
data_essai_2$test[[2]]
data_essai_2$train[[1]]
data_essai_2$train[[2]]
data_essai_2 <- crossv_kfold(data_essai, k = 3, id = ".id")
data_essai_2$test[[1]]
data_essai_2$test[[2]]
data_essai_2$test[[3]]
data_essai_2$train[[1]]
data_essai_2$train[[2]]
data_essai_2$train[[3]]
?resample
data_essai_2$train[[1]]
data_essai_2$train[[2]]
data_essai_2$train[[3]]
data_essai2_df <- as.data.frame(data_essai_2)
View(data_essai2_df)
data_essai2_df <- as.data.frame(data_essai_2$train[[1]]
data_essai2_df <- as.data.frame(data_essai_2$train[[1]])
data_essai2_df <- as.data.frame(data_essai_2$train[[1]])
data_essai_2$train[[1]]
data_essai_2$train[[2]]
data_essai_2$train[[3]]
as.integer(data_essai_2$train[[1]])
resample(data_essai, 2)
resample(data_essai, 1:2)
resample(data_essai, 1:3)
a <- resample(data_essai, 1:3)
as.data.frame(a)
a <- resample(data_essai, 1:2)
as.data.frame(a)
View(cv)
as.integer(cv$train[1])
as.integer(cv$train[[1]])
as.integer(cv$train[[2]])
as.integer(cv$test[[2]])
as.integer(cv$test[[1]])
as.integer(cv$train[[1]])
as.integer(cv$test[[1]])
filter(!is.na(author)
author_data_nona <- author_data %>%
author_data_nona <- author_data %>%
filter(!is.na(author))
folds <- crossv_kfold(author_data_nona, k = nrow(author_data_nona), id = id)
folds <- crossv_kfold(author_data_nona, k = nrow(author_data_nona), id = ".id")
View(folds)
as.integer(folds$test[[1]])
as.integer(folds$train[[1]])
folds <- crossv_kfold(author_data_nona, k = 65, id = ".id")
as.integer(folds$train[[1]])
as.integer(folds$test[[1]])
as.integer(folds$train[[1]])
View(author_data_nona)
View(models)
View(models)
?lm
lm(author2 ~ upon + there + consequently + whilst, data = cv$train, model = FALSE)
lm(data = cv$train, author2 ~ upon + there + consequently + whilst, model = FALSE)
lm(data = cv$train[[1]], author2 ~ upon + there + consequently + whilst, model = FALSE)
lm(author2 ~ upon + there + consequently + whilst, data = cv$train[[1]], model = FALSE)
lm(author2 ~ upon + there + consequently + whilst, data = cv$train[[2]], model = FALSE)
models <- purrr::mutate(model = map(cv$train, ~ lm(author2 ~ upon + there + consequently + whilst,
data = ., model = FALSE)))
models <- mutate(model = map(cv$train, ~ lm(author2 ~ upon + there + consequently + whilst,
data = ., model = FALSE)))
models <- model = map(cv$train, ~ lm(author2 ~ upon + there + consequently + whilst,
data = ., model = FALSE))
models <- purrr::map(cv$train, ~ lm(author2 ~ upon + there + consequently + whilst,
data = ., model = FALSE))
mod_fun <- function(df){
lm(author2 ~ upon + there + consequently + whilst, data = df, model = FALSE)
}
models_1 <- cv$train %>%
mutate(model = map(data, mod_fun))
models <- purrr::map(cv$train,  lm(author2 ~ upon + there + consequently + whilst,
data = ., model = FALSE))
models <- purrr::map(cv$train, ~ lm(author2 ~ upon + there + consequently + whilst,
data = ., model = FALSE))
mod_fun <- function(df){
lm(author2 ~ upon + there + consequently + whilst,
data = ., model = FALSE)
}
models1 <- purrr::map(cv$train, mod_fun)
mod_fun <- function(df){
lm(author2 ~ upon + there + consequently + whilst,
data = df, model = FALSE)
}
models1 <- purrr::map(cv$train, mod_fun)
map2_
View(author_data)
View(hm_fit)
author_data <- author_data %>%
add_predictions(hm_fit)
View(author_data)
author_data <- author_data %>%
add_predictions(hm_fit) %>%
mutate(pred_author = if_else(pred >= 0, "Hamilton", "Madison"))
author_data %>%
filter(!is.na(author)) %>%
group_by(author) %>%
mutate(pcorect = if_else(author == pred_author, 1, 0 )) %>%
summarise(`Proportion Correct` = mean(pcorect))
author_data %>%
filter(!is.na(author)) %>%
group_by(author) %>%
mutate(pcorect = if_else(author == pred_author, 1, 0))
author_data %>%
filter(!is.na(author)) %>%
group_by(author) %>%
mutate(pcorect = if_else(author == pred_author, 1, 0)) %>%
summarise(`Proportion Correct` = mean(pcorect))
View(test)
## créer une fonction avec deux argument
mod_fun2 <- function(mod, test){
add_predictions(as.data.frame(test), mod) %>%
mutate(pred_author = if_else(pred >= 0, "Hamilton", "Madison"),
correct = (pred_author == author))
}
test2 <- map2_df(models, cv$test, mod_fun2)
test3 <- map2_df(models, cv$test,
~
add_predictions(as.data.frame(..), .) %>%
mutate(pred_author = if_else(pred >= 0, "Hamilton", "Madison"),
correct = (pred_author == author)))
test3 <- map2_df(models, cv$test,
~
add_predictions(as.data.frame(.y), .x) %>%
mutate(pred_author = if_else(pred >= 0, "Hamilton", "Madison"),
correct = (pred_author == author)))
View(test3)
View(test2)
View(test)
test3 <- map2_df(models, cv$test,
~ add_predictions(as.data.frame(.y), .x) %>%
mutate(pred_author = if_else(pred >= 0, "Hamilton", "Madison"),
correct = (pred_author == author)))
test %>%
group_by(author) %>%
summarise(mean(correct))
author_data %>%
filter(is.na(author)) %>%
select(id_num, pred, pred_author) %>%
knitr::kable()
View(test)
?enframe()
enframe(kmean_out$cluster, "id_num", "cluster")
View(kmean_out)
enframe(1:3)
enframe(c(a = 5, b = 7))
c(a = 5, b = 7)
enframe(c(a = 5, b = 7))
list(one = 1, two = 2:3, three = 4:6)
enframe(list(one = 1, two = 2:3, three = 4:6))
kmean_out$cluster[[1]]
kmean_out$cluster[[2]]
kmean_out$cluster[[3]]
kmean_out$cluster[[67]]
kmean_out$cluster[[1]][1]
tidy(kmean_out$cluster)
tidy(kmean_out$cluster) %>%
group_by(X) %>%
summarise(documents = str_c(names, collapse = ", "))
tidy(kmean_out$cluster) %>%
group_by(x) %>%
summarise(documents = str_c(names, collapse = ", "))
tidy(kmean_out$cluster) %>%
group_by(x) %>%
summarise(documents = str_c(names, collapse = ", "))
ggplot(doc12_24) +
geom_col(aes(x = reorder(word, desc(n)), y = n, fill = id), show.legend = FALSE) +
labs(x = "Word") +
coord_flip() +
facet_grid(~ id, scales = "free") # +
ggplot(doc12_24) +
geom_col(aes(x = reorder(word, desc(n)), y = n, fill = id), show.legend = FALSE) +
# labs(x = "Word") +
coord_flip() +
facet_grid(~ id, scales = "free") # +
disputed_essays <- filter(author_data, is.na(author))$id_num
ggplot(mutate(author_data,
author = fct_na_value_to_level(author, "Disputed")),
aes(y = id_num, x = pred, colour = author, shape = author)) +
geom_ref_line(v = 0) +
geom_point() +
scale_y_continuous(breaks = seq(10, 80, by = 10),
minor_breaks = seq(5, 80, by = 5)) +
scale_color_manual(values = c("Madison" = "blue",
"Hamilton" = "red",
"Disputed" = "black")) +
scale_shape_manual(values = c("Madison" = 16, "Hamilton" = 15,
"Disputed" = 17)) +
labs(colour = "Author", shape = "Author",
y = "Federalist Papers", x = "Predicted values")
ggplot(mutate(author_data,
author = fct_na_value_to_level(author, "Disputed")),
aes(y = id_num, x = pred, colour = author, shape = author)) +
geom_ref_line(v = 0) +
geom_point() +
scale_y_continuous(breaks = seq(10, 80, by = 10),
minor_breaks = seq(5, 80, by = 5)) +
scale_color_manual(values = c("Madison" = "blue",
"Hamilton" = "red",
"Disputed" = "black")) +
scale_shape_manual(values = c("Madison" = 10, "Hamilton" = 15,
"Disputed" = 17)) +
labs(colour = "Author", shape = "Author",
y = "Federalist Papers", x = "Predicted values")
ggplot(mutate(author_data,
author = fct_na_value_to_level(author, "Disputed")),
aes(y = id_num, x = pred, colour = author, shape = author)) +
geom_ref_line(v = 0) +
geom_point() +
scale_y_continuous(breaks = seq(10, 80, by = 10),
minor_breaks = seq(5, 80, by = 5)) +
scale_color_manual(values = c("Madison" = "blue",
"Hamilton" = "red",
"Disputed" = "black")) +
scale_shape_manual(values = c("Madison" = 20, "Hamilton" = 15,
"Disputed" = 17)) +
labs(colour = "Author", shape = "Author",
y = "Federalist Papers", x = "Predicted values")
ggplot(mutate(author_data,
author = fct_na_value_to_level(author, "Disputed")),
aes(y = id_num, x = pred, colour = author, shape = author)) +
geom_ref_line(v = 0) +
geom_point() +
scale_y_continuous(breaks = seq(10, 80, by = 10),
minor_breaks = seq(5, 80, by = 5)) +
scale_color_manual(values = c("Madison" = "blue",
"Hamilton" = "red",
"Disputed" = "black")) +
scale_shape_manual(values = c("Madison" = 16, "Hamilton" = 15,
"Disputed" = 17)) +
labs(colour = "Author", shape = "Author",
y = "Federalist Papers", x = "Predicted values")
# Charger les informations additionnelles -- Les données sur la population
census <- read_csv("https://raw.githubusercontent.com/compsocialscience/summer-institute/master/2020/materials/day4-surveys/activity/2017_acs_data_clean.csv")
write_csv(census, file = "../Data/census.csv")
census1 <- read_csv("../Data/census.csv")
View(census1)
(20*180 +40*170)/60
